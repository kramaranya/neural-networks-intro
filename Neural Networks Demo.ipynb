{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3bfdbca-492b-4594-bc11-61b2cf4eb634",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "### Anya Kramar - Kubeflow DevX Team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777dd7c9-5fc3-4b16-8d7b-c01c0965910d",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31d270f-f4f0-4801-bda1-6e8f69740a64",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Mathematical models inspired by the human brain</li>\n",
    "    <li>Learn patterns from data without explicit programming</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Why are Neural Networks Important?</h3>\n",
    "<ul>\n",
    "    <li>Solve problems traditional algorithms can't handle</li>\n",
    "    <li>Power everyday technologies we rely on:\n",
    "        <ul>\n",
    "            <li>Voice assistants</li>\n",
    "            <li>Recommendation systems</li>\n",
    "            <li>Image recognition</li>\n",
    "            <li>Language translation</li>\n",
    "            <li>Self‑driving car technologies</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Continue to push AI boundaries forward</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943bbee4-25b1-4adb-bcde-b956cb783624",
   "metadata": {},
   "source": [
    "## Biological Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5e6ca4-3ed6-4fca-bd3d-5eb4c09570ea",
   "metadata": {},
   "source": [
    "<p>Neural networks are loosely inspired by the structure and function of the human brain.</p>\n",
    "<div style=\"text-align:center;\">\n",
    "    <figure>\n",
    "        <img src=\"https://cdn.i-scmp.com/sites/default/files/styles/1020x680/public/d8/images/methode/2020/07/10/ad89450a-c1d5-11ea-8c85-9f30eae6654e_image_hires_194031.JPG?itok=PdRHJEj7&v=1594381242\" width=\"300\"/>\n",
    "    </figure>\n",
    "</div>\n",
    "\n",
    "<h3>How Biological Neurons Work</h3>\n",
    "<ul>\n",
    "    <li>The human brain contains billions of neurons</li>\n",
    "    <li>Each neuron is connected to thousands of others</li>\n",
    "    <li>Key components:\n",
    "        <ul>\n",
    "            <li><b>Dendrites:</b> receive signals</li>\n",
    "            <li><b>Cell Body:</b> processes signals</li>\n",
    "            <li><b>Axon:</b> transmits signals</li>\n",
    "            <li><b>Synapses:</b> connections between neurons</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>When enough input signals arrive in a short time, the neuron “fires,” sending an electrical pulse down the axon</li>\n",
    "    <li>This signal may then activate other connected neurons</li>\n",
    "</ul>\n",
    "<div style=\"text-align:center;\">\n",
    "    <figure>\n",
    "        <img src=\"https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/1223/2017/02/07195441/Figure_35_01_02-1024x687.png\" width=\"600\"/>\n",
    "    </figure>\n",
    "</div>\n",
    "\n",
    "<h3>Biological vs. Artificial Neural Networks</h3>\n",
    "<ul>\n",
    "    <li>Artificial neural networks are <b>simplified mathematical models</b> of biological neural systems</li>\n",
    "    <li>The human brain has about 86 billion neurons with trillions of connections</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96c1b47-c5a9-4e45-96b7-feed01bebc3f",
   "metadata": {},
   "source": [
    "## Artifical Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1ba259-cbed-48b0-b69b-da4c6ae26e37",
   "metadata": {},
   "source": [
    "<h3>What is a neuron?</h3>\n",
    "<p>An artificial neuron is a mathematical function designed to mimic the basic behaviour of a biological neuron.</p>\n",
    "<ul>\n",
    "    <li>Takes multiple inputs (features from our data)</li>\n",
    "    <li>Processes them</li>\n",
    "    <li>Produces an output value</li>\n",
    "</ul>\n",
    "<div style=\"text-align:center;\">\n",
    "    <figure>\n",
    "        <img src=\"https://www.oreilly.com/api/v2/epubs/9781789346565/files/assets/46651759-ddc3-4669-8e1b-827bc63b1eca.png\" width=\"500\"/>\n",
    "    </figure>\n",
    "</div>\n",
    "<h3>Components of an Artificial Neuron</h3>\n",
    "<ul>\n",
    "    <li>Real‑valued inputs: \\(x_1, x_2, \\ldots, x_n\\)</li>\n",
    "    <li>Weights for each input: \\(w_1, w_2, \\ldots, w_n\\)</li>\n",
    "    <li>Bias \\(b\\)</li>\n",
    "    <li>Weighted sum:\n",
    "        \\[\n",
    "            z = b + w_1x_1 + w_2x_2 + \\dots + w_nx_n\n",
    "        \\]\n",
    "    </li>\n",
    "    <li>Activation function: transforms \\(z\\) into final output</li>\n",
    "</ul>\n",
    "<h3>Weights and Bias</h3>\n",
    "<ul>\n",
    "    <li><b>Weights</b> set the importance of each input</li>\n",
    "    <li><b>Bias</b> lets the neuron fire even when inputs are zero</li>\n",
    "    <li>Training adjusts weights and biases to minimise prediction errors</li>\n",
    "</ul>\n",
    "\n",
    "<h3>Activation Functions</h3>\n",
    "<li>The neuron then usually applies an <b>activation function</b>, $g$, to the weighted sum, $z$.\n",
    "        Many activation functions have been proposed, including:\n",
    "        <ul>\n",
    "            <li><b>linear activation function</b>: $$g(z) = z$$</li>\n",
    "            <li><b>step activation function</b>:\n",
    "                $$g(z) = \\left\\{ \\begin{array}{lr}\n",
    "                    0 & \\mbox{if } z < 0 \\\\\n",
    "                    1 & \\mbox{if } z \\geq 0\n",
    "                    \\end{array}\n",
    "                  \\right.\n",
    "                $$\n",
    "            </li>\n",
    "            <li><b>sigmoid activation function</b>: $$g(z) = \\frac{1}{1 + e^{-z}}$$</li>\n",
    "            <li><b>ReLU activation function</b> (ReLU stands for Rectified Linear Unit): $$g(z) = max(0, z)$$</li>\n",
    "            <li><b>tanh activation function</b> (tanh is the hyperbolic tangent): $$g(z) = \\tanh(z)$$\n",
    "                <li><b>softmax activation function</b> (multi‑class output):\n",
    "        $$g(z_i)=\\frac{e^{z_i}}{\\sum_j e^{z_j}}$$\n",
    "        produces a vector of values in (0, 1) that sum to 1.\n",
    "    </li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Apart from the linear activation function, these activation functions are <b>non-linear</b>, which\n",
    "        is important to the power of neural networks.\n",
    "    </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012d0f72-1d28-4244-9c14-0439523b5c12",
   "metadata": {},
   "source": [
    "## Layers of Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5bae65-fd91-457a-bb06-ba8bfa9aec53",
   "metadata": {},
   "source": [
    "<p>Neural networks are built from layers of neurons; each layer processes inputs and passes outputs on.</p>\n",
    "<div style=\"text-align:center;\">\n",
    "    <figure>\n",
    "        <img src=\"https://cs231n.github.io/assets/nn1/neural_net.jpeg\" width=\"500\"/>\n",
    "    </figure>\n",
    "</div>\n",
    "\n",
    "<p>These multi-layer networks have a distinct structure:</p>\n",
    "<ul>\n",
    "    <li><b>Input layer</b>: receives raw data</li>\n",
    "    <li><b>Hidden layers</b>: do most computations and extract features</li>\n",
    "    <li><b>Output layer</b>: produces final prediction</li>\n",
    "</ul>\n",
    "<p>When we talk about a network's <b>depth</b> - we're referring to the number of layers of neurons it contains. This is why modern approaches are called \"deep learning\" - they use networks with many layers.</p>\n",
    "<p>What happens between these layers? Under the hood, it's mostly matrix multiplication.</p>\n",
    "\n",
    "<p>The networks we're discussing now are called <b>layered</b>, <b>dense</b>, <b>feedforward</b> networks.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9975ddf-0761-4c41-9cb0-33ae8ff7e285",
   "metadata": {},
   "source": [
    "## Learning of a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f62bbc8-02c4-4783-83f3-53612594e37e",
   "metadata": {},
   "source": [
    "<li>While we're responsible for deciding the network architecture and hyperparameters, the network itself learns the optimal parameter values:\n",
    "    <ul>\n",
    "        <li>The <b>parameters</b> of a neural network are its weights and biases</li>\n",
    "        <li>These parameters are what get updated during training</li>\n",
    "    </ul>\n",
    "</li>\n",
    "\n",
    "<h3>The Training Process</h3>\n",
    "        <li><b>Initialization</b>: We start by assigning random small values to all weights and biases</li>\n",
    "        <li><b>Forward Propagation</b>: Data flows through the network, with each layer performing its calculations</li>\n",
    "        <li><b>Loss Calculation</b>: We measure how far our predictions are from the true values using a <b>loss function</b></li>\n",
    "        <li><b>Backpropagation</b>: The error is propagated backward through the network to determine how each weight contributed</li>\n",
    "        <li><b>Weight Update</b>: We adjust weights and biases to reduce error using an optimization algorithm</li>\n",
    "    </ul>\n",
    "<p>We repeat these steps with more data until the model converges to a solution.</p>\n",
    "\n",
    "\n",
    "<h3>Key Concepts in Neural Network Learning</h3>\n",
    "<ul>\n",
    "    <li><b>Loss Function</b>: shows how far predictions are from true values\n",
    "        <ul>\n",
    "            <li>Mean Squared Error (MSE) for regression</li>\n",
    "            <li>Cross‑Entropy Loss for classification</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Optimizer that moves weights toward lower error\n",
    "        <ul>\n",
    "            <li>Learning rate sets the step size</li>\n",
    "            <li>If too high, training can diverge</li>\n",
    "            <li>If too low, training is slow</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li><b>Epochs</b>: one full pass through the training set</li>\n",
    "    <li><b>Batch Size</b>: number of samples per update step</li>\n",
    "    <li><b>Overfitting</b>: great on training data but poor on new data</li>\n",
    "    <li><b>Learning Approaches</b>:\n",
    "        <ul>\n",
    "            <li><b>Supervised Learning</b>: learn from labelled examples</li>\n",
    "            <li><b>Unsupervised Learning</b>: find structure without labels</li>\n",
    "            <li><b>Reinforcement Learning</b>: learn by interacting with an environment</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfce85bf-21a1-4f5a-94a6-b891c8b31310",
   "metadata": {},
   "source": [
    "## Types of Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb821f62-e135-463a-b6fe-7d0445b41ff9",
   "metadata": {},
   "source": [
    "<li><b>Feedforward Networks</b>:\n",
    "    <ul>\n",
    "        <li>Information flows in only one direction - from input to output</li>\n",
    "        <li>They have no \"memory\" of previous inputs</li>\n",
    "        <li>They form the foundation that all other architectures build upon</li>\n",
    "    </ul>\n",
    "</li>\n",
    "\n",
    "<li><b>Single-layer Perceptron</b>:\n",
    "    <ul>\n",
    "        <li>It consists of just one layer of neurons</li>\n",
    "        <li>It can only solve <b>linearly separable</b> problems</li>\n",
    "    </ul>\n",
    "</li>\n",
    "\n",
    "<li><b>Multilayer Perceptrons (MLPs)</b>:\n",
    "    <ul>\n",
    "        <li>By adding hidden layers with non-linear activation functions, these networks overcame the limitations of single-layer perceptrons</li>\n",
    "    </ul>\n",
    "</li>\n",
    "\n",
    "<li><b>Convolutional Neural Networks (CNNs)</b> :\n",
    "    <ul>\n",
    "        <li>Designed for image processing</li>\n",
    "        <li>Uses convolutional layers to automatically learn hierarchical features from input images</li>\n",
    "    </ul>\n",
    "</li>\n",
    "\n",
    "<li><b>Recurrent Neural Networks (RNNs)</b>:\n",
    "    <ul>\n",
    "        <li>Unlike feedforward networks, RNNs have connections that form cycles</li>\n",
    "        <li>These feedback loops allow information to persist, giving the network a form of \"memory\"</li>\n",
    "        <li>This makes them ideal for tasks where context and order matter</li>\n",
    "    </ul>\n",
    "</li>\n",
    "\n",
    "<li><b>Long Short-Term Memory (LSTM)</b>:\n",
    "    <ul>\n",
    "        <li>LSTMs are a special type of RNN with a more complex cell structure</li>\n",
    "        <li>They use ingenious \"gates\" to control what information to remember, what to update, and what to output</li>\n",
    "        <li>This allows them to capture long-range dependencies much more effectively</li>\n",
    "        <li>They're important for language processing, speech recognition, and time series forecasting</li>\n",
    "    </ul>\n",
    "</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3c3dea-0977-4f5a-ac43-6a3e01b959fc",
   "metadata": {},
   "source": [
    "## Implementation of Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ecc80631-8aa8-41f7-91ec-45764b786e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, Normalization, Rescaling\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788c754d-7f07-47b3-9e34-c31962c8a23e",
   "metadata": {},
   "source": [
    "<h2>Introduction</h2>\n",
    "<ul>\n",
    "    <li>We load the <b>Titanic</b> dataset with <code>seaborn.load_dataset</code>, shuffle it,\n",
    "        split 80 % train / 20 % test, and convert to NumPy arrays.</li>\n",
    "    <li>We will reuse the same DataFrame but choose different targets for each task:\n",
    "        <ul>\n",
    "            <li><b>Regression:</b> predict <code>fare</code></li>\n",
    "            <li><b>Binary classification:</b> predict <code>survived</code></li>\n",
    "            <li><b>Multi‑class classification:</b> predict passenger class (<code>pclass</code>)</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Categorical inputs (<code>sex</code> and <code>embarked</code>) are one‑hot encoded with <code>pd.get_dummies</code>.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6c528b9f-16d9-4401-a7b6-6298140eef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load, shuffle, split once\n",
    "titanic_df = sns.load_dataset(\"titanic\").dropna(subset=[\"age\", \"fare\", \"embarked\"])\n",
    "titanic_df = titanic_df.sample(frac=1, random_state=2).reset_index(drop=True)\n",
    "\n",
    "train_df, test_df = train_test_split(titanic_df, train_size=0.8, random_state=2)\n",
    "\n",
    "# One‑hot encode categorical columns (drop_first avoids redundancy)\n",
    "train_df = pd.get_dummies(train_df, columns=[\"sex\", \"embarked\"], drop_first=True)\n",
    "test_df  = pd.get_dummies(test_df,  columns=[\"sex\", \"embarked\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a7acdada-357e-422a-a144-55e5a191d892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.2375</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>E</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.5000</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>Third</td>\n",
       "      <td>child</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Second</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>D</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass   age  sibsp  parch     fare   class    who  adult_male  \\\n",
       "544         0       3  61.0      0      0   6.2375   Third    man        True   \n",
       "440         0       3  33.0      0      0   7.8958   Third    man        True   \n",
       "13          0       1  65.0      0      0  26.5500   First    man        True   \n",
       "486         1       1  35.0      1      0  90.0000   First  woman       False   \n",
       "411         0       2  28.0      0      0  13.5000  Second    man        True   \n",
       "40          0       3   8.0      4      1  29.1250   Third  child       False   \n",
       "205         0       2  36.0      0      0  13.0000  Second    man        True   \n",
       "65          0       2  30.0      0      0  13.0000  Second    man        True   \n",
       "72          1       2  36.0      0      0  13.0000  Second  woman       False   \n",
       "304         0       2  70.0      0      0  10.5000  Second    man        True   \n",
       "\n",
       "    deck  embark_town alive  alone  sex_male  embarked_Q  embarked_S  \n",
       "544  NaN  Southampton    no   True      True       False        True  \n",
       "440  NaN  Southampton    no   True      True       False        True  \n",
       "13     E  Southampton    no   True      True       False        True  \n",
       "486    C  Southampton   yes  False     False       False        True  \n",
       "411  NaN  Southampton    no   True      True       False        True  \n",
       "40   NaN   Queenstown    no  False      True        True       False  \n",
       "205  NaN  Southampton    no   True      True       False        True  \n",
       "65   NaN  Southampton    no   True      True       False        True  \n",
       "72     D  Southampton   yes   True     False       False        True  \n",
       "304  NaN  Southampton    no   True      True       False        True  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b800493-092e-4b86-9b96-6860f8b55eff",
   "metadata": {},
   "source": [
    "<h1>A Neural Network for Regression</h1>\n",
    "<ul>\n",
    "    <li>Task: estimate a passenger’s <code>fare</code> from simple attributes.</li>\n",
    "    <li>Architecture:\n",
    "        <ul>\n",
    "            <li>Input layer with 7 inputs (<i>age, sibsp, parch, pclass, sex_male, embarked_Q, embarked_S</i>).</li>\n",
    "            <li>Two hidden layers, 64 neurons each, ReLU activation.</li>\n",
    "            <li>Single linear output neuron.</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "b596898c-0b45-448e-8ad6-73bf9fef902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_features = [\"age\", \"sibsp\", \"parch\", \"pclass\", \"sex_male\", \"embarked_Q\", \"embarked_S\"]\n",
    "\n",
    "train_X = train_df[reg_features].to_numpy(dtype=\"float32\")\n",
    "test_X  = test_df[reg_features].to_numpy(dtype=\"float32\")\n",
    "train_y = train_df[\"fare\"].to_numpy(dtype=\"float32\")\n",
    "test_y  = test_df[\"fare\"].to_numpy(dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "76a9491d-ef91-405a-8053-0e0235f50241",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(len(reg_features),))\n",
    "x = Normalization()(inputs)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "outputs = Dense(1, activation=\"linear\")(x)\n",
    "fare_model = Model(inputs, outputs)\n",
    "\n",
    "fare_model.compile(optimizer=RMSprop(0.001), loss=\"mse\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "3ffae860-0212-4486-b776-fe703e503c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - loss: 3535.4402 - mae: 30.3641\n",
      "Epoch 2/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step - loss: 2787.0029 - mae: 26.5208\n",
      "Epoch 3/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - loss: 3438.6038 - mae: 29.0416\n",
      "Epoch 4/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 4510.0522 - mae: 32.5407\n",
      "Epoch 5/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - loss: 2245.5208 - mae: 26.7276\n",
      "Epoch 6/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 3148.0759 - mae: 30.5827\n",
      "Epoch 7/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - loss: 2739.0881 - mae: 29.3444\n",
      "Epoch 8/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - loss: 2828.3499 - mae: 27.6538\n",
      "Epoch 9/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 2429.4473 - mae: 25.5850\n",
      "Epoch 10/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - loss: 2425.3984 - mae: 27.7385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x37be91c40>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fare_model.fit(train_X, train_y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "95ec9ebe-766a-49d1-b419-6ac0a26b9539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - loss: 3650.2295 - mae: 30.2567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27.988588333129883"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_mae = fare_model.evaluate(test_X, test_y)\n",
    "test_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f859e5a3-b596-4625-a3b1-d8a195d14235",
   "metadata": {},
   "source": [
    "<h1>A Neural Network for Binary Classification</h1>\n",
    "<ul>\n",
    "    <li>Task: predict whether a passenger <code>survived</code> (0 or 1).</li>\n",
    "    <li>Same input attributes as before.</li>\n",
    "    <li>Output layer: one neuron with sigmoid activation.</li>\n",
    "    <li>We'll scale inputs inside the model with a <code>Normalization</code> layer\n",
    "        to avoid data‑leakage worries.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c8d5f07b-d27a-4730-b5e1-9a5d02046ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_features = reg_features\n",
    "\n",
    "train_Xb = train_df[bin_features].to_numpy(dtype=\"float32\")\n",
    "test_Xb  = test_df[bin_features].to_numpy(dtype=\"float32\")\n",
    "train_yb = train_df[\"survived\"].to_numpy(dtype=\"float32\")\n",
    "test_yb  = test_df[\"survived\"].to_numpy(dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "cfe493bf-3d0a-4ee4-add7-4bc2a9d585eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(len(bin_features),))\n",
    "x = Normalization()(inputs)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "surv_model = Model(inputs, outputs)\n",
    "\n",
    "surv_model.compile(optimizer=RMSprop(0.001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b77ac6e1-078a-4a97-85c6-dac1d492c475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.5411 - loss: 1.3075\n",
      "Epoch 2/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.6194 - loss: 0.6495\n",
      "Epoch 3/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.6498 - loss: 0.6162\n",
      "Epoch 4/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - accuracy: 0.6774 - loss: 0.6022\n",
      "Epoch 5/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - accuracy: 0.6912 - loss: 0.6073\n",
      "Epoch 6/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333us/step - accuracy: 0.7055 - loss: 0.5777\n",
      "Epoch 7/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - accuracy: 0.6987 - loss: 0.5973\n",
      "Epoch 8/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.7054 - loss: 0.5953\n",
      "Epoch 9/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7242 - loss: 0.5387\n",
      "Epoch 10/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.7231 - loss: 0.5681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x381df7640>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surv_model.fit(train_Xb, train_yb, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "4c5d078f-2b2a-4edb-a157-45d4645cf88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.7887 - loss: 0.5455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7762237787246704"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_acc = surv_model.evaluate(test_Xb, test_yb)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9a2bb2-678d-4424-b2bd-2093b8042101",
   "metadata": {},
   "source": [
    "<h1>A Neural Network for Multi‑Class Classification</h1>\n",
    "<ul>\n",
    "    <li>Task: predict passenger class (<code>pclass</code> = 1, 2 or 3).</li>\n",
    "    <li>Same 7 inputs.</li>\n",
    "    <li>Output layer: three neurons with softmax activation.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a0383234-72bf-45ec-bbf0-9acb7683241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_features = reg_features\n",
    "\n",
    "train_Xm = train_df[multi_features].to_numpy(dtype=\"float32\")\n",
    "test_Xm  = test_df[multi_features].to_numpy(dtype=\"float32\")\n",
    "train_ym = (train_df[\"pclass\"] - 1).to_numpy(dtype=\"float32\")\n",
    "test_ym  = (test_df[\"pclass\"] - 1).to_numpy(dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b406a9e4-8164-4089-a335-8a36663720ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(len(multi_features),))\n",
    "x = Normalization()(inputs)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "outputs = Dense(3, activation=\"softmax\")(x)\n",
    "class_model = Model(inputs, outputs)\n",
    "\n",
    "class_model.compile(optimizer=RMSprop(0.001), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a9b9ce7a-cfef-465f-9960-aedca24f5025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.3659 - loss: 2.5451\n",
      "Epoch 2/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.5325 - loss: 1.0109\n",
      "Epoch 3/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - accuracy: 0.6353 - loss: 0.8401\n",
      "Epoch 4/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.6628 - loss: 0.7536\n",
      "Epoch 5/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.6696 - loss: 0.7378\n",
      "Epoch 6/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313us/step - accuracy: 0.6504 - loss: 0.7696\n",
      "Epoch 7/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.6849 - loss: 0.6758\n",
      "Epoch 8/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.6918 - loss: 0.6545\n",
      "Epoch 9/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.7317 - loss: 0.5983\n",
      "Epoch 10/10\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.7401 - loss: 0.5829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x37bf13dc0>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_model.fit(train_Xm, train_ym, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "70464108-59cf-4919-b727-314ca336c13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.7522 - loss: 0.5410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7762237787246704"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_acc = class_model.evaluate(test_Xm, test_ym)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b442d7d2-87fa-4960-808f-6777cee9cd5b",
   "metadata": {},
   "source": [
    "## Applications of Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308b1d03-f60d-4c67-86aa-5ef76897e034",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li><b>Image and Video Recognition</b>: CNNs are extensively used in applications such as facial recognition, autonomous driving, and medical image analysis.</li>\n",
    "    <li><b>Natural Language Processing (NLP)</b>: RNNs and transformers power language translation, chatbots, and sentiment analysis.</li>\n",
    "    <li><b>Finance</b>: Predicting stock prices, fraud detection, and risk management.</li>\n",
    "    <li><b>Healthcare</b>: Neural networks assist in diagnosing diseases, analyzing medical images, and personalizing treatment plans.</li>\n",
    "    <li><b>Gaming and Autonomous Systems</b>: Neural networks enable real-time decision-making, enhancing user experience in video games and enabling autonomous systems like self-driving cars.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bef8b52-da31-4c5b-89b9-79869ff990f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
